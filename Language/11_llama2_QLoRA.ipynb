{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOSRrNr5XkEMWLd+1rB6cw9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36d7a7eaea354a368446e674eebf7ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_189967f5a3964fa2a80d2d04b1acdaf2",
              "IPY_MODEL_0fd7d0fee0494f1480703cb219950e40",
              "IPY_MODEL_b43eee065eff4694be7ad34a73100a1e"
            ],
            "layout": "IPY_MODEL_7bff90b62b6248faa455e0dd35dc3262"
          }
        },
        "189967f5a3964fa2a80d2d04b1acdaf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbe62ecbbc724d0db0367901839f7929",
            "placeholder": "​",
            "style": "IPY_MODEL_f9d0fd366ff8402693d8364c435b917b",
            "value": "tokenizer.json: 100%"
          }
        },
        "0fd7d0fee0494f1480703cb219950e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d69feff202134e1e8f4e0ff99dde6cf1",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2367e862e6fb4ee3a5dc669aa6be2c89",
            "value": 1842767
          }
        },
        "b43eee065eff4694be7ad34a73100a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2b0b01528c34961b65b6598e4dcdcc8",
            "placeholder": "​",
            "style": "IPY_MODEL_b486fa51deaa401da165fa7f74906ec4",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 11.1MB/s]"
          }
        },
        "7bff90b62b6248faa455e0dd35dc3262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbe62ecbbc724d0db0367901839f7929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9d0fd366ff8402693d8364c435b917b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d69feff202134e1e8f4e0ff99dde6cf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2367e862e6fb4ee3a5dc669aa6be2c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2b0b01528c34961b65b6598e4dcdcc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b486fa51deaa401da165fa7f74906ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63f92e6f57d84d82b8200956dfe63674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1da4ca1b48ea498c8fd76fa5acb3185f",
              "IPY_MODEL_5f8bd0ef84924fa984dbfe80ec5b78c2",
              "IPY_MODEL_fdc8b6b59a6d44659344b9503d1e4181"
            ],
            "layout": "IPY_MODEL_df959526751144e1be45f0d73655b916"
          }
        },
        "1da4ca1b48ea498c8fd76fa5acb3185f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_228dd804ebb8481bb2d19ee3c79c3e13",
            "placeholder": "​",
            "style": "IPY_MODEL_93211143d64e450dbcde4b6e652574f0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "5f8bd0ef84924fa984dbfe80ec5b78c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4990ae66dd33443292a0025621bcdcf3",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_348fc61315284dbe8a48fb6df9dc7ab3",
            "value": 2
          }
        },
        "fdc8b6b59a6d44659344b9503d1e4181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_012302ad891f4d2fb131d0ec162089a4",
            "placeholder": "​",
            "style": "IPY_MODEL_a1d9dce784d94ce9a65d6c091243fddd",
            "value": " 2/2 [01:06&lt;00:00, 30.36s/it]"
          }
        },
        "df959526751144e1be45f0d73655b916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "228dd804ebb8481bb2d19ee3c79c3e13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93211143d64e450dbcde4b6e652574f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4990ae66dd33443292a0025621bcdcf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "348fc61315284dbe8a48fb6df9dc7ab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "012302ad891f4d2fb131d0ec162089a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1d9dce784d94ce9a65d6c091243fddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peisuke/generative_ai_notebooks/blob/main/11_llama2_QLoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# パッケージのインストール\n",
        "!git clone https://github.com/artidoro/qlora\n",
        "%cd qlora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v-0bE5478bH",
        "outputId": "818afc13-bd6f-4ddf-9163-5e0e49898670"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'qlora'...\n",
            "remote: Enumerating objects: 578, done.\u001b[K\n",
            "remote: Total 578 (delta 0), reused 0 (delta 0), pack-reused 578\u001b[K\n",
            "Receiving objects: 100% (578/578), 30.63 MiB | 16.20 MiB/s, done.\n",
            "Resolving deltas: 100% (369/369), done.\n",
            "Updating files: 100% (274/274), done.\n",
            "/content/qlora\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z6q5RU18CfM",
        "outputId": "fa4b3c48-6441-4425-c879-b2c0ef906ecc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes==0.40.0 (from -r requirements.txt (line 1))\n",
            "  Downloading bitsandbytes-0.40.0-py3-none-any.whl (91.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.31.0 (from -r requirements.txt (line 2))\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft==0.4.0 (from -r requirements.txt (line 3))\n",
            "  Downloading peft-0.4.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.21.0 (from -r requirements.txt (line 4))\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops==0.6.1 (from -r requirements.txt (line 5))\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate==0.4.0 (from -r requirements.txt (line 6))\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.2.2)\n",
            "Collecting sentencepiece==0.1.99 (from -r requirements.txt (line 8))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb==0.15.3 (from -r requirements.txt (line 9))\n",
            "  Downloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r requirements.txt (line 2)) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r requirements.txt (line 2)) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r requirements.txt (line 2)) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r requirements.txt (line 2)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r requirements.txt (line 2)) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r requirements.txt (line 2)) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0->-r requirements.txt (line 2))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r requirements.txt (line 2)) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0->-r requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0->-r requirements.txt (line 3)) (2.1.0+cu118)\n",
            "Collecting datasets>=2.0.0 (from evaluate==0.4.0->-r requirements.txt (line 6))\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from evaluate==0.4.0->-r requirements.txt (line 6))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->-r requirements.txt (line 6)) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->-r requirements.txt (line 6)) (3.4.1)\n",
            "Collecting multiprocess (from evaluate==0.4.0->-r requirements.txt (line 6))\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->-r requirements.txt (line 6)) (2023.6.0)\n",
            "Collecting responses<0.19 (from evaluate==0.4.0->-r requirements.txt (line 6))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->-r requirements.txt (line 7)) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->-r requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->-r requirements.txt (line 7)) (3.2.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3->-r requirements.txt (line 9)) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb==0.15.3->-r requirements.txt (line 9))\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb==0.15.3->-r requirements.txt (line 9))\n",
            "  Downloading sentry_sdk-1.38.0-py2.py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb==0.15.3->-r requirements.txt (line 9))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb==0.15.3->-r requirements.txt (line 9))\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb==0.15.3->-r requirements.txt (line 9))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3->-r requirements.txt (line 9)) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3->-r requirements.txt (line 9)) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3->-r requirements.txt (line 9)) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.4.0->-r requirements.txt (line 6)) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets>=2.0.0->evaluate==0.4.0->-r requirements.txt (line 6))\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.4.0->-r requirements.txt (line 6)) (3.9.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb==0.15.3->-r requirements.txt (line 9)) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb==0.15.3->-r requirements.txt (line 9))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0->-r requirements.txt (line 2)) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r requirements.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r requirements.txt (line 2)) (2023.11.17)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 3)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 3)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 3)) (2.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.4.0->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.4.0->-r requirements.txt (line 6)) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r requirements.txt (line 6)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r requirements.txt (line 6)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r requirements.txt (line 6)) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r requirements.txt (line 6)) (4.0.3)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.15.3->-r requirements.txt (line 9))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 3)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 3)) (1.3.0)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8793 sha256=bf03f5fc53b55c6af3614b832b5e246b7179154c6370a37d189836c08612cb3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: tokenizers, sentencepiece, pathtools, bitsandbytes, smmap, setproctitle, sentry-sdk, pyarrow-hotfix, einops, docker-pycreds, dill, responses, multiprocess, gitdb, transformers, GitPython, accelerate, wandb, peft, datasets, evaluate\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed GitPython-3.1.40 accelerate-0.21.0 bitsandbytes-0.40.0 datasets-2.15.0 dill-0.3.7 docker-pycreds-0.4.0 einops-0.6.1 evaluate-0.4.0 gitdb-4.0.11 multiprocess-0.70.15 pathtools-0.1.2 peft-0.4.0 pyarrow-hotfix-0.6 responses-0.18.0 sentencepiece-0.1.99 sentry-sdk-1.38.0 setproctitle-1.3.3 smmap-5.0.1 tokenizers-0.13.3 transformers-4.31.0 wandb-0.15.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSCjVxC07Ux5",
        "outputId": "cfe14769-7529-4130-f24c-3318aeb02b35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'shi3z/anthropic_hh_rlhf_japanese'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Total 36 (delta 0), reused 0 (delta 0), pack-reused 36\u001b[K\n",
            "Unpacking objects:   2% (1/36)\rUnpacking objects:   5% (2/36)\rUnpacking objects:   8% (3/36)\rUnpacking objects:  11% (4/36)\rUnpacking objects:  13% (5/36)\rUnpacking objects:  16% (6/36)\rUnpacking objects:  19% (7/36)\rUnpacking objects:  22% (8/36)\rUnpacking objects:  25% (9/36)\rUnpacking objects:  27% (10/36)\rUnpacking objects:  30% (11/36)\rUnpacking objects:  33% (12/36)\rUnpacking objects:  36% (13/36)\rUnpacking objects:  38% (14/36)\rUnpacking objects:  41% (15/36)\rUnpacking objects:  44% (16/36)\rUnpacking objects:  47% (17/36)\rUnpacking objects:  50% (18/36)\rUnpacking objects:  52% (19/36)\rUnpacking objects:  55% (20/36)\rUnpacking objects:  58% (21/36)\rUnpacking objects:  61% (22/36)\rUnpacking objects:  63% (23/36)\rUnpacking objects:  66% (24/36)\rUnpacking objects:  69% (25/36)\rUnpacking objects:  72% (26/36)\rUnpacking objects:  75% (27/36)\rUnpacking objects:  77% (28/36)\rUnpacking objects:  80% (29/36)\rUnpacking objects:  83% (30/36)\rUnpacking objects:  86% (31/36)\rUnpacking objects:  88% (32/36)\rUnpacking objects:  91% (33/36)\rUnpacking objects:  94% (34/36)\rUnpacking objects:  97% (35/36)\rUnpacking objects: 100% (36/36)\rUnpacking objects: 100% (36/36), 4.15 KiB | 606.00 KiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://huggingface.co/datasets/shi3z/anthropic_hh_rlhf_japanese shi3z/anthropic_hh_rlhf_japanese"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HuggingFaceのログイン\n",
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnE_GSfd8CyD",
        "outputId": "a2972669-412b-4655-cda2-51b7bbb2733d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習の実行\n",
        "!python qlora.py \\\n",
        "    --model_name meta-llama/Llama-2-7b-hf \\\n",
        "    --output_dir \"./output/peft\" \\\n",
        "    --dataset_name shi3z/anthropic_hh_rlhf_japanese\\\n",
        "    --max_steps 1000 \\\n",
        "    --use_auth \\\n",
        "    --logging_steps 10 \\\n",
        "    --save_strategy steps \\\n",
        "    --data_seed 42 \\\n",
        "    --save_steps 200 \\\n",
        "    --save_total_limit 40 \\\n",
        "    --max_new_tokens 32 \\\n",
        "    --dataloader_num_workers 1 \\\n",
        "    --group_by_length \\\n",
        "    --logging_strategy steps \\\n",
        "    --remove_unused_columns False \\\n",
        "    --do_train \\\n",
        "    --lora_r 64 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_modules all \\\n",
        "    --double_quant \\\n",
        "    --quant_type nf4 \\\n",
        "    --fp16 \\\n",
        "    --bits 4 \\\n",
        "    --warmup_ratio 0.03 \\\n",
        "    --lr_scheduler_type constant \\\n",
        "    --gradient_checkpointing \\\n",
        "    --source_max_len 16 \\\n",
        "    --target_max_len 512 \\\n",
        "    --per_device_train_batch_size 1 \\\n",
        "    --gradient_accumulation_steps 16 \\\n",
        "    --eval_steps 187 \\\n",
        "    --learning_rate 0.0002 \\\n",
        "    --adam_beta2 0.999 \\\n",
        "    --max_grad_norm 0.3 \\\n",
        "    --lora_dropout 0.1 \\\n",
        "    --weight_decay 0.0 \\\n",
        "    --seed 0 \\\n",
        "    --load_in_4bit \\\n",
        "    --use_peft \\\n",
        "    --batch_size 4 \\\n",
        "    --gradient_accumulation_steps 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAW8KSpB8E_O",
        "outputId": "f3dcc11e-7ee3-4e9e-d117-627f191db535"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//172.28.0.1'), PosixPath('http'), PosixPath('8013')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-2sb565necxv3t --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//ipykernel.pylab.backend_inline'), PosixPath('module')}\n",
            "  warn(msg)\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n",
            "2023-12-12 12:17:37.040561: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-12 12:17:37.040614: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-12 12:17:37.040648: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-12 12:17:38.149174: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Namespace(model_name_or_path='meta-llama/Llama-2-7b-hf', trust_remote_code=False, use_auth_token=True, eval_dataset_size=1024, max_train_samples=None, max_eval_samples=None, source_max_len=16, target_max_len=512, dataset='alpaca', dataset_format=None, output_dir='./output/peft', overwrite_output_dir=False, do_train=True, do_eval=False, do_predict=False, evaluation_strategy=<IntervalStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=2, eval_accumulation_steps=None, eval_delay=0, learning_rate=0.0002, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=0.3, num_train_epochs=3.0, max_steps=1000, lr_scheduler_type=<SchedulerType.CONSTANT: 'constant'>, warmup_ratio=0.03, warmup_steps=0, log_level='passive', log_level_replica='warning', log_on_each_node=True, logging_dir='./output/peft/runs/Dec12_12-17-40_19ec8397dc48', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=10, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=50, save_total_limit=40, save_safetensors=False, save_on_each_node=False, no_cuda=False, use_mps_device=False, seed=0, data_seed=42, jit_mode_eval=False, use_ipex=False, bf16=False, fp16=True, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=0, ddp_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=187.0, dataloader_num_workers=1, past_index=-1, run_name='./output/peft', disable_tqdm=False, remove_unused_columns=False, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], fsdp=[], fsdp_min_num_params=0, fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}, fsdp_transformer_layer_cls_to_wrap=None, deepspeed=None, label_smoothing_factor=0.0, optim=<OptimizerNames.PAGED_ADAMW: 'paged_adamw_32bit'>, optim_args=None, adafactor=False, group_by_length=True, length_column_name='length', report_to=[], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, ddp_broadcast_buffers=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, hub_private_repo=False, gradient_checkpointing=True, include_inputs_for_metrics=False, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', auto_find_batch_size=False, full_determinism=False, torchdynamo=None, ray_scope='last', ddp_timeout=1800, torch_compile=False, torch_compile_backend=None, torch_compile_mode=None, xpu_backend=None, sortish_sampler=False, predict_with_generate=False, generation_max_length=None, generation_num_beams=None, generation_config=GenerationConfig {\n",
            "  \"max_new_tokens\": 32,\n",
            "  \"transformers_version\": \"4.31.0\"\n",
            "}\n",
            ", cache_dir=None, train_on_source=False, mmlu_split='eval', mmlu_dataset='mmlu-fs', do_mmlu_eval=False, max_mmlu_samples=None, mmlu_source_max_len=2048, full_finetune=False, adam8bit=False, double_quant=True, quant_type='nf4', bits=4, lora_r=64, lora_alpha=16.0, lora_dropout=0.1, max_memory_MB=80000, distributed_state=Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            ", _n_gpu=1, __cached__setup_devices=device(type='cuda', index=0), deepspeed_plugin=None)\n",
            "loading base model meta-llama/Llama-2-7b-hf...\n",
            "config.json: 100% 609/609 [00:00<00:00, 3.50MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "model.safetensors.index.json: 100% 26.8k/26.8k [00:00<00:00, 89.1MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/9.98G [00:00<00:59, 168MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/9.98G [00:00<00:42, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 83.9M/9.98G [00:00<00:39, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 115M/9.98G [00:00<00:36, 269MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 147M/9.98G [00:00<00:36, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 178M/9.98G [00:00<00:37, 261MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 210M/9.98G [00:00<00:38, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 241M/9.98G [00:00<00:39, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 273M/9.98G [00:01<00:39, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 304M/9.98G [00:01<00:38, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 336M/9.98G [00:01<00:38, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 367M/9.98G [00:01<00:39, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 398M/9.98G [00:01<00:39, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 430M/9.98G [00:01<00:39, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 461M/9.98G [00:01<00:39, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 493M/9.98G [00:01<00:38, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 524M/9.98G [00:02<00:37, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 556M/9.98G [00:02<00:37, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 587M/9.98G [00:02<00:36, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 619M/9.98G [00:02<00:35, 265MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 650M/9.98G [00:02<00:34, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 682M/9.98G [00:02<00:35, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 713M/9.98G [00:02<00:36, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 744M/9.98G [00:02<00:38, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 776M/9.98G [00:03<00:39, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 807M/9.98G [00:03<00:41, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 839M/9.98G [00:03<00:41, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 870M/9.98G [00:03<00:41, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 902M/9.98G [00:03<00:41, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 933M/9.98G [00:03<00:40, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 965M/9.98G [00:03<00:38, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 996M/9.98G [00:04<00:42, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 1.03G/9.98G [00:04<00:42, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.06G/9.98G [00:04<00:43, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.09G/9.98G [00:04<00:43, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.12G/9.98G [00:04<00:42, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.15G/9.98G [00:04<00:42, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.18G/9.98G [00:05<00:40, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.22G/9.98G [00:05<00:39, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.25G/9.98G [00:05<00:39, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.28G/9.98G [00:05<00:40, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.31G/9.98G [00:05<00:39, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.34G/9.98G [00:05<00:37, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.37G/9.98G [00:05<00:42, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.41G/9.98G [00:06<00:41, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.44G/9.98G [00:06<00:41, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.47G/9.98G [00:07<01:38, 86.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.49G/9.98G [00:07<01:38, 86.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.52G/9.98G [00:07<01:15, 111MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.54G/9.98G [00:07<01:15, 112MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.56G/9.98G [00:07<01:12, 116MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.58G/9.98G [00:07<01:06, 127MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.60G/9.98G [00:08<00:59, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.64G/9.98G [00:08<00:49, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.67G/9.98G [00:08<00:44, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.70G/9.98G [00:08<00:41, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.73G/9.98G [00:08<00:38, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.76G/9.98G [00:08<00:37, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.79G/9.98G [00:08<00:35, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.82G/9.98G [00:08<00:35, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.86G/9.98G [00:09<00:34, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.89G/9.98G [00:09<00:34, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.92G/9.98G [00:09<00:34, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.95G/9.98G [00:09<00:34, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.98G/9.98G [00:09<00:33, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.01G/9.98G [00:09<00:32, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.04G/9.98G [00:09<00:31, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.08G/9.98G [00:09<00:29, 265MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.11G/9.98G [00:10<00:28, 272MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.14G/9.98G [00:10<00:32, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.17G/9.98G [00:10<00:31, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.20G/9.98G [00:10<00:32, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.23G/9.98G [00:10<00:32, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.26G/9.98G [00:10<00:32, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.30G/9.98G [00:10<00:32, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.33G/9.98G [00:10<00:32, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.36G/9.98G [00:11<00:32, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.39G/9.98G [00:11<00:32, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.42G/9.98G [00:11<00:32, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.45G/9.98G [00:11<00:31, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.49G/9.98G [00:11<00:30, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.52G/9.98G [00:11<00:29, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.55G/9.98G [00:11<00:28, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.58G/9.98G [00:12<00:29, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.61G/9.98G [00:12<00:29, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.64G/9.98G [00:12<00:29, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.67G/9.98G [00:12<00:29, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.71G/9.98G [00:12<00:28, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.74G/9.98G [00:12<00:28, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.77G/9.98G [00:12<00:27, 265MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.80G/9.98G [00:12<00:26, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.83G/9.98G [00:12<00:27, 261MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.86G/9.98G [00:13<00:30, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.89G/9.98G [00:13<00:30, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.93G/9.98G [00:13<00:30, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.96G/9.98G [00:13<00:29, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.99G/9.98G [00:13<00:29, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.02G/9.98G [00:13<00:29, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.05G/9.98G [00:13<00:29, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.08G/9.98G [00:14<00:28, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.11G/9.98G [00:14<00:28, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.15G/9.98G [00:14<00:27, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.18G/9.98G [00:14<00:28, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.21G/9.98G [00:14<00:28, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.24G/9.98G [00:14<00:40, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.27G/9.98G [00:15<00:35, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.30G/9.98G [00:15<00:31, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.33G/9.98G [00:15<00:29, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.37G/9.98G [00:15<00:28, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.40G/9.98G [00:15<00:29, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.43G/9.98G [00:15<00:28, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.46G/9.98G [00:15<00:27, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.49G/9.98G [00:17<01:57, 55.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.52G/9.98G [00:17<01:30, 71.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.55G/9.98G [00:17<01:11, 90.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.59G/9.98G [00:17<00:57, 111MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.62G/9.98G [00:17<00:49, 128MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.65G/9.98G [00:18<00:47, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.67G/9.98G [00:18<00:44, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.69G/9.98G [00:18<00:42, 148MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.71G/9.98G [00:18<00:40, 153MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.73G/9.98G [00:18<00:38, 160MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.75G/9.98G [00:22<05:28, 18.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.79G/9.98G [00:22<03:33, 29.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.81G/9.98G [00:22<02:45, 37.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.83G/9.98G [00:22<02:12, 46.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.85G/9.98G [00:22<01:46, 57.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.87G/9.98G [00:22<01:25, 71.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.89G/9.98G [00:23<01:10, 86.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.92G/9.98G [00:23<00:53, 113MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.95G/9.98G [00:23<00:45, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.98G/9.98G [00:23<00:38, 156MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.02G/9.98G [00:23<00:34, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.05G/9.98G [00:23<00:30, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.08G/9.98G [00:23<00:28, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.11G/9.98G [00:24<00:26, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.14G/9.98G [00:24<00:25, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.17G/9.98G [00:24<00:25, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.20G/9.98G [00:24<00:25, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.24G/9.98G [00:24<00:24, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.27G/9.98G [00:26<01:38, 58.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.29G/9.98G [00:26<01:22, 68.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.32G/9.98G [00:26<01:02, 90.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.35G/9.98G [00:26<00:50, 112MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.38G/9.98G [00:27<01:53, 49.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.41G/9.98G [00:27<01:25, 64.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.45G/9.98G [00:28<01:05, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.48G/9.98G [00:28<00:50, 108MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.51G/9.98G [00:28<00:41, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.54G/9.98G [00:28<00:35, 152MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.57G/9.98G [00:28<00:30, 176MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.60G/9.98G [00:28<00:27, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.63G/9.98G [00:28<00:25, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.67G/9.98G [00:28<00:24, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.70G/9.98G [00:29<00:22, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.73G/9.98G [00:29<00:21, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.76G/9.98G [00:29<00:21, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.79G/9.98G [00:29<00:20, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.82G/9.98G [00:29<00:20, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.85G/9.98G [00:29<00:20, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.89G/9.98G [00:29<00:20, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.92G/9.98G [00:29<00:20, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.95G/9.98G [00:30<00:20, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.98G/9.98G [00:30<00:20, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.01G/9.98G [00:30<00:20, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.04G/9.98G [00:30<00:20, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.08G/9.98G [00:30<00:20, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.11G/9.98G [00:30<00:20, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.14G/9.98G [00:30<00:21, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.17G/9.98G [00:30<00:22, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.20G/9.98G [00:31<00:22, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.23G/9.98G [00:31<00:23, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.25G/9.98G [00:31<00:23, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.28G/9.98G [00:31<00:22, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.32G/9.98G [00:31<00:21, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.35G/9.98G [00:31<00:21, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.38G/9.98G [00:32<00:21, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.41G/9.98G [00:32<00:21, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.44G/9.98G [00:32<00:21, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.47G/9.98G [00:32<00:20, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.51G/9.98G [00:32<00:33, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.53G/9.98G [00:32<00:30, 147MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.56G/9.98G [00:33<00:25, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.59G/9.98G [00:33<00:23, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.62G/9.98G [00:33<00:21, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.65G/9.98G [00:33<00:21, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.68G/9.98G [00:33<00:31, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.70G/9.98G [00:34<00:29, 143MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.74G/9.98G [00:34<00:26, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.77G/9.98G [00:34<00:23, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.80G/9.98G [00:34<00:21, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.83G/9.98G [00:34<00:20, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.86G/9.98G [00:34<00:19, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.89G/9.98G [00:34<00:18, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.92G/9.98G [00:34<00:17, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.96G/9.98G [00:35<00:17, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.99G/9.98G [00:35<00:16, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.02G/9.98G [00:35<00:16, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.05G/9.98G [00:35<00:15, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.08G/9.98G [00:35<00:15, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.11G/9.98G [00:35<00:16, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.14G/9.98G [00:35<00:15, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.18G/9.98G [00:35<00:15, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.21G/9.98G [00:36<00:15, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.24G/9.98G [00:36<00:15, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.27G/9.98G [00:36<00:14, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.30G/9.98G [00:36<00:14, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.33G/9.98G [00:36<00:14, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.36G/9.98G [00:36<00:13, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.40G/9.98G [00:36<00:14, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.43G/9.98G [00:36<00:14, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.46G/9.98G [00:37<00:14, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.49G/9.98G [00:37<00:14, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.52G/9.98G [00:37<00:13, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.55G/9.98G [00:37<00:13, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.59G/9.98G [00:37<00:13, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.62G/9.98G [00:37<00:13, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.65G/9.98G [00:37<00:13, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.68G/9.98G [00:37<00:12, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.71G/9.98G [00:38<00:12, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.74G/9.98G [00:38<00:12, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.77G/9.98G [00:38<00:12, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.81G/9.98G [00:38<00:12, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.84G/9.98G [00:38<00:11, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.87G/9.98G [00:38<00:11, 271MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.90G/9.98G [00:38<00:11, 275MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.93G/9.98G [00:38<00:11, 268MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.96G/9.98G [00:39<00:12, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.99G/9.98G [00:39<00:12, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 7.03G/9.98G [00:39<00:12, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.06G/9.98G [00:39<00:12, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.09G/9.98G [00:39<00:11, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.12G/9.98G [00:39<00:11, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.15G/9.98G [00:39<00:11, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.18G/9.98G [00:39<00:11, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.21G/9.98G [00:40<00:10, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.25G/9.98G [00:40<00:10, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.28G/9.98G [00:40<00:11, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.31G/9.98G [00:40<00:11, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.34G/9.98G [00:40<00:11, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.37G/9.98G [00:42<01:03, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.39G/9.98G [00:42<00:51, 50.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.41G/9.98G [00:43<00:42, 59.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.43G/9.98G [00:43<00:35, 71.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.46G/9.98G [00:43<00:29, 84.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.48G/9.98G [00:43<00:24, 100MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.50G/9.98G [00:43<00:21, 116MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.52G/9.98G [00:43<00:19, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.54G/9.98G [00:43<00:16, 144MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.57G/9.98G [00:43<00:14, 167MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.60G/9.98G [00:44<00:12, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.62G/9.98G [00:44<00:12, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.64G/9.98G [00:44<00:12, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.68G/9.98G [00:44<00:11, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.71G/9.98G [00:44<00:11, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.73G/9.98G [00:44<00:11, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.76G/9.98G [00:44<00:10, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.79G/9.98G [00:44<00:09, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.82G/9.98G [00:45<00:09, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.85G/9.98G [00:45<00:10, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.89G/9.98G [00:45<00:09, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.92G/9.98G [00:45<00:09, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.95G/9.98G [00:45<00:08, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.98G/9.98G [00:45<00:08, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 8.01G/9.98G [00:46<00:09, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.04G/9.98G [00:46<00:12, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.07G/9.98G [00:46<00:11, 168MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.11G/9.98G [00:46<00:10, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.14G/9.98G [00:46<00:09, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.16G/9.98G [00:46<00:10, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.18G/9.98G [00:47<00:10, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.21G/9.98G [00:47<00:09, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.24G/9.98G [00:47<00:08, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.27G/9.98G [00:47<00:08, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.30G/9.98G [00:47<00:08, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.33G/9.98G [00:47<00:09, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.35G/9.98G [00:47<00:09, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.38G/9.98G [00:48<00:08, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.41G/9.98G [00:48<00:07, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.44G/9.98G [00:48<00:06, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.47G/9.98G [00:48<00:06, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.50G/9.98G [00:48<00:06, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.54G/9.98G [00:48<00:05, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.57G/9.98G [00:48<00:05, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.60G/9.98G [00:48<00:05, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.63G/9.98G [00:49<00:05, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.66G/9.98G [00:49<00:05, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.69G/9.98G [00:49<00:05, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.72G/9.98G [00:49<00:05, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.76G/9.98G [00:49<00:05, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.79G/9.98G [00:49<00:05, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.82G/9.98G [00:49<00:04, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.85G/9.98G [00:49<00:04, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.88G/9.98G [00:50<00:04, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.91G/9.98G [00:50<00:04, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.94G/9.98G [00:50<00:04, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.98G/9.98G [00:50<00:04, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 9.01G/9.98G [00:50<00:03, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.04G/9.98G [00:50<00:03, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.07G/9.98G [00:50<00:03, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.10G/9.98G [00:51<00:03, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.13G/9.98G [00:51<00:03, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.16G/9.98G [00:51<00:03, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.20G/9.98G [00:51<00:03, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.23G/9.98G [00:51<00:02, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.26G/9.98G [00:51<00:02, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.29G/9.98G [00:51<00:02, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.32G/9.98G [00:51<00:02, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.35G/9.98G [00:52<00:02, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.38G/9.98G [00:52<00:02, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.42G/9.98G [00:52<00:02, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.45G/9.98G [00:52<00:02, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.48G/9.98G [00:52<00:01, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.51G/9.98G [00:52<00:01, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.54G/9.98G [00:52<00:01, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.57G/9.98G [00:52<00:01, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.60G/9.98G [00:53<00:01, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.64G/9.98G [00:53<00:01, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.67G/9.98G [00:53<00:01, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.70G/9.98G [00:53<00:01, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.73G/9.98G [00:53<00:00, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.76G/9.98G [00:53<00:00, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.79G/9.98G [00:53<00:00, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.83G/9.98G [00:53<00:00, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.86G/9.98G [00:53<00:00, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.89G/9.98G [00:54<00:00, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.92G/9.98G [00:54<00:00, 268MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.98G/9.98G [00:54<00:00, 183MB/s]\n",
            "Downloading shards:  50% 1/2 [00:54<00:54, 54.65s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 21.0M/3.50G [00:00<00:22, 158MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 41.9M/3.50G [00:00<00:19, 175MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 73.4M/3.50G [00:00<00:17, 198MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 105M/3.50G [00:00<00:15, 212MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 136M/3.50G [00:00<00:15, 219MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 168M/3.50G [00:00<00:15, 219MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 199M/3.50G [00:00<00:14, 222MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 231M/3.50G [00:01<00:14, 231MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 262M/3.50G [00:01<00:13, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 294M/3.50G [00:01<00:13, 244MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 325M/3.50G [00:01<00:12, 247MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 357M/3.50G [00:01<00:12, 245MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 388M/3.50G [00:01<00:12, 248MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 419M/3.50G [00:01<00:12, 244MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 451M/3.50G [00:01<00:12, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 482M/3.50G [00:02<00:11, 253MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 514M/3.50G [00:02<00:12, 249MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 545M/3.50G [00:02<00:12, 246MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 577M/3.50G [00:02<00:11, 247MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 608M/3.50G [00:02<00:11, 244MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 640M/3.50G [00:02<00:11, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 671M/3.50G [00:02<00:11, 244MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 703M/3.50G [00:02<00:11, 246MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 734M/3.50G [00:03<00:11, 232MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 765M/3.50G [00:03<00:11, 238MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 797M/3.50G [00:03<00:10, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 828M/3.50G [00:03<00:10, 260MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 860M/3.50G [00:03<00:10, 249MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 891M/3.50G [00:03<00:11, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 923M/3.50G [00:05<00:38, 66.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 954M/3.50G [00:05<00:29, 85.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 986M/3.50G [00:05<00:23, 107MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 1.02G/3.50G [00:05<00:19, 129MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 1.05G/3.50G [00:05<00:17, 141MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.08G/3.50G [00:05<00:16, 150MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.10G/3.50G [00:05<00:15, 156MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 1.13G/3.50G [00:06<00:14, 169MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 1.15G/3.50G [00:06<00:13, 171MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.18G/3.50G [00:06<00:12, 185MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 1.22G/3.50G [00:06<00:11, 195MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 1.25G/3.50G [00:06<00:10, 205MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.28G/3.50G [00:06<00:10, 208MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.31G/3.50G [00:06<00:10, 208MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 1.34G/3.50G [00:06<00:09, 220MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.37G/3.50G [00:07<00:10, 195MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.39G/3.50G [00:07<00:11, 188MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.42G/3.50G [00:07<00:10, 192MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 1.45G/3.50G [00:07<00:10, 198MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.48G/3.50G [00:10<00:59, 33.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.51G/3.50G [00:10<00:42, 47.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.53G/3.50G [00:10<00:35, 55.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.55G/3.50G [00:10<00:29, 66.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 1.57G/3.50G [00:10<00:24, 79.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.59G/3.50G [00:10<00:20, 94.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.61G/3.50G [00:10<00:17, 110MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 1.65G/3.50G [00:10<00:14, 131MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 1.68G/3.50G [00:11<00:11, 153MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.71G/3.50G [00:11<00:10, 171MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.73G/3.50G [00:11<00:10, 177MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.76G/3.50G [00:11<00:08, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.79G/3.50G [00:11<00:08, 205MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 1.82G/3.50G [00:11<00:07, 211MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 1.86G/3.50G [00:11<00:07, 223MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 1.89G/3.50G [00:11<00:06, 232MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.92G/3.50G [00:12<00:06, 231MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 1.95G/3.50G [00:12<00:09, 161MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 1.98G/3.50G [00:12<00:08, 184MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.01G/3.50G [00:12<00:07, 199MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.04G/3.50G [00:12<00:07, 205MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 2.08G/3.50G [00:12<00:06, 211MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 2.11G/3.50G [00:13<00:06, 218MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 2.14G/3.50G [00:13<00:06, 217MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 2.17G/3.50G [00:13<00:05, 227MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 2.20G/3.50G [00:13<00:05, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.23G/3.50G [00:13<00:05, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 2.26G/3.50G [00:13<00:05, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 2.30G/3.50G [00:13<00:05, 237MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.33G/3.50G [00:14<00:04, 236MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.36G/3.50G [00:14<00:04, 240MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 2.39G/3.50G [00:14<00:04, 240MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 2.42G/3.50G [00:14<00:04, 242MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 2.45G/3.50G [00:14<00:04, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 2.49G/3.50G [00:14<00:04, 237MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 2.52G/3.50G [00:14<00:04, 243MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 2.55G/3.50G [00:14<00:03, 252MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 2.58G/3.50G [00:15<00:03, 245MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.61G/3.50G [00:15<00:06, 129MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.64G/3.50G [00:15<00:05, 154MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 2.67G/3.50G [00:15<00:04, 179MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 2.71G/3.50G [00:15<00:04, 189MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.74G/3.50G [00:16<00:03, 198MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 2.77G/3.50G [00:16<00:03, 208MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 2.80G/3.50G [00:16<00:03, 216MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.83G/3.50G [00:16<00:03, 217MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 2.86G/3.50G [00:16<00:02, 218MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 2.89G/3.50G [00:16<00:02, 226MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.93G/3.50G [00:16<00:02, 232MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.96G/3.50G [00:17<00:02, 231MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 2.99G/3.50G [00:17<00:02, 237MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 3.02G/3.50G [00:17<00:02, 230MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.05G/3.50G [00:17<00:01, 236MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 3.08G/3.50G [00:17<00:01, 242MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 3.11G/3.50G [00:17<00:01, 225MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 3.15G/3.50G [00:17<00:01, 227MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 3.18G/3.50G [00:17<00:01, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 3.21G/3.50G [00:18<00:01, 230MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 3.24G/3.50G [00:18<00:01, 207MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 3.27G/3.50G [00:18<00:01, 190MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 3.30G/3.50G [00:18<00:01, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 3.32G/3.50G [00:18<00:00, 192MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 3.34G/3.50G [00:20<00:02, 53.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 3.38G/3.50G [00:20<00:01, 73.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 3.41G/3.50G [00:20<00:00, 95.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 3.43G/3.50G [00:20<00:00, 105MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 3.45G/3.50G [00:20<00:00, 115MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 3.47G/3.50G [00:20<00:00, 128MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 3.50G/3.50G [00:20<00:00, 168MB/s]\n",
            "Downloading shards: 100% 2/2 [01:15<00:00, 37.82s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [01:25<00:00, 42.75s/it]\n",
            "generation_config.json: 100% 188/188 [00:00<00:00, 1.07MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 409MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 2.51MB/s]\n",
            "tokenizer_config.json: 100% 776/776 [00:00<00:00, 4.79MB/s]\n",
            "Adding special tokens.\n",
            "adding LoRA modules...\n",
            "loaded model\n",
            "Downloading readme: 100% 7.47k/7.47k [00:00<00:00, 25.1MB/s]\n",
            "Downloading data files:   0% 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0% 0.00/24.2M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  17% 4.19M/24.2M [00:00<00:00, 30.1MB/s]\u001b[A\n",
            "Downloading data:  52% 12.6M/24.2M [00:00<00:00, 47.1MB/s]\u001b[A\n",
            "Downloading data: 100% 24.2M/24.2M [00:00<00:00, 54.8MB/s]\n",
            "Downloading data files: 100% 1/1 [00:00<00:00,  2.25it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1491.57it/s]\n",
            "Generating train split: 52002 examples [00:00, 257263.30 examples/s]\n",
            "Map: 100% 52002/52002 [00:03<00:00, 14767.35 examples/s]\n",
            "Map: 100% 52002/52002 [00:02<00:00, 25017.66 examples/s]\n",
            "trainable params: 79953920.0 || all params: 3660328960 || trainable: 2.1843370056007205\n",
            "torch.float32 422326272 0.11537932153507864\n",
            "torch.uint8 3238002688 0.8846206784649213\n",
            "  0% 0/1000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.4681, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            "{'loss': 1.655, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            "{'loss': 2.0525, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            "{'loss': 2.4035, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            "{'loss': 2.8285, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            "  5% 50/1000 [01:31<22:45,  1.44s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.541, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            "{'loss': 1.4777, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            "{'loss': 2.2638, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            "{'loss': 2.7468, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            "{'loss': 2.7697, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            " 10% 100/1000 [03:28<22:28,  1.50s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.5096, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            "{'loss': 1.5024, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            "{'loss': 2.0006, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            "{'loss': 2.1829, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 2.8513, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            " 15% 150/1000 [05:50<22:13,  1.57s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.5996, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 1.4989, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 1.8595, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 2.3233, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 2.5033, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            " 20% 200/1000 [08:00<19:39,  1.47s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.5555, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 1.5289, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 1.7354, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 2.1646, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 2.5242, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            " 25% 250/1000 [10:15<18:39,  1.49s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.5563, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 1.4282, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 1.6811, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 2.9296, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 2.3483, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            " 30% 300/1000 [12:10<17:11,  1.47s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.4277, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 1.6948, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 2.2684, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 2.2662, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 2.2513, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            " 35% 350/1000 [14:20<16:20,  1.51s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.6215, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 1.6379, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 1.8262, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 1.9161, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 3.0662, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            " 40% 400/1000 [16:10<14:55,  1.49s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.4804, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 1.7237, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 2.3132, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 2.2353, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 2.2553, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            " 45% 450/1000 [18:04<13:30,  1.47s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.4598, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 1.5261, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 1.563, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 1.7564, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 2.1577, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            " 50% 500/1000 [19:56<12:33,  1.51s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.4275, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 1.4564, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 1.6533, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 2.1443, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 2.3578, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            " 55% 550/1000 [21:50<11:11,  1.49s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.3798, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 1.4747, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 1.7516, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 2.6238, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 2.4411, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            " 60% 600/1000 [23:53<09:48,  1.47s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.649, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 1.5199, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 1.9565, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 2.2351, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 2.7531, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            " 65% 650/1000 [25:44<08:33,  1.47s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.4697, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 1.5806, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 1.7073, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 2.1662, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 2.5148, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            " 70% 700/1000 [27:42<07:22,  1.47s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.5139, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 1.4754, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 1.7173, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 2.2406, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 2.3193, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            " 75% 750/1000 [29:31<06:10,  1.48s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.4714, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 1.4999, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 1.7713, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 2.3804, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 3.2287, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            " 80% 800/1000 [31:23<04:55,  1.48s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.4807, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 1.6149, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 1.764, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 2.1024, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 2.534, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            " 85% 850/1000 [33:14<03:42,  1.49s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.4028, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 1.5171, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 1.6163, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 2.6611, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 2.3788, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            " 90% 900/1000 [35:02<02:26,  1.47s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.489, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 1.5192, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            "{'loss': 1.7096, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            "{'loss': 2.5576, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            "{'loss': 2.4, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            " 95% 950/1000 [37:00<01:13,  1.47s/it]Saving PEFT checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.3919, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            "{'loss': 1.5808, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            "{'loss': 1.9566, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            "{'loss': 2.1493, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            "{'loss': 2.668, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            "100% 1000/1000 [38:55<00:00,  1.53s/it]Saving PEFT checkpoint...\n",
            "{'train_runtime': 2357.4788, 'train_samples_per_second': 0.848, 'train_steps_per_second': 0.424, 'train_loss': 1.9531219816207885, 'epoch': 0.04}\n",
            "100% 1000/1000 [39:17<00:00,  2.36s/it]\n",
            "Saving PEFT checkpoint...\n",
            "***** train metrics *****\n",
            "  epoch                    =       0.04\n",
            "  train_loss               =     1.9531\n",
            "  train_runtime            = 0:39:17.47\n",
            "  train_samples_per_second =      0.848\n",
            "  train_steps_per_second   =      0.424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "# トークナイザーとモデルの読み込み\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"meta-llama/Llama-2-7b-hf\"\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Llama-2-7b-hf\",\n",
        "    quantization_config=BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    ),\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689,
          "referenced_widgets": [
            "36d7a7eaea354a368446e674eebf7ba8",
            "189967f5a3964fa2a80d2d04b1acdaf2",
            "0fd7d0fee0494f1480703cb219950e40",
            "b43eee065eff4694be7ad34a73100a1e",
            "7bff90b62b6248faa455e0dd35dc3262",
            "cbe62ecbbc724d0db0367901839f7929",
            "f9d0fd366ff8402693d8364c435b917b",
            "d69feff202134e1e8f4e0ff99dde6cf1",
            "2367e862e6fb4ee3a5dc669aa6be2c89",
            "f2b0b01528c34961b65b6598e4dcdcc8",
            "b486fa51deaa401da165fa7f74906ec4",
            "63f92e6f57d84d82b8200956dfe63674",
            "1da4ca1b48ea498c8fd76fa5acb3185f",
            "5f8bd0ef84924fa984dbfe80ec5b78c2",
            "fdc8b6b59a6d44659344b9503d1e4181",
            "df959526751144e1be45f0d73655b916",
            "228dd804ebb8481bb2d19ee3c79c3e13",
            "93211143d64e450dbcde4b6e652574f0",
            "4990ae66dd33443292a0025621bcdcf3",
            "348fc61315284dbe8a48fb6df9dc7ab3",
            "012302ad891f4d2fb131d0ec162089a4",
            "a1d9dce784d94ce9a65d6c091243fddd"
          ]
        },
        "id": "V12EhX-9_XRm",
        "outputId": "cfd52c21-71f4-4cf2-b48d-d9bb25474c8f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//172.28.0.1'), PosixPath('8013'), PosixPath('http')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-2sb565necxv3t --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true'), PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36d7a7eaea354a368446e674eebf7ba8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63f92e6f57d84d82b8200956dfe63674"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRAの読み込み\n",
        "model = PeftModel.from_pretrained(\n",
        "    model,\n",
        "    \"./output/peft/checkpoint-1000/adapter_model/\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImulPvHE9f39",
        "outputId": "987d513c-9a64-4a1b-9825-13ac508f77f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear4bit(\n",
              "                in_features=4096, out_features=4096, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k_proj): Linear4bit(\n",
              "                in_features=4096, out_features=4096, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (v_proj): Linear4bit(\n",
              "                in_features=4096, out_features=4096, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o_proj): Linear4bit(\n",
              "                in_features=4096, out_features=4096, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear4bit(\n",
              "                in_features=4096, out_features=11008, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=11008, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (up_proj): Linear4bit(\n",
              "                in_features=4096, out_features=11008, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=11008, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (down_proj): Linear4bit(\n",
              "                in_features=11008, out_features=4096, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=11008, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (act_fn): SiLUActivation()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm()\n",
              "            (post_attention_layernorm): LlamaRMSNorm()\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# プロンプトの準備\n",
        "prompt = \"### Instruction: 機械学習って何?\\n\\n### Response: \"\n",
        "\n",
        "# 推論の実行\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(**inputs, max_new_tokens=100)"
      ],
      "metadata": {
        "id": "lEF1nr6gAhE-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOYNubYmAkRr",
        "outputId": "83996176-625d-43ff-e636-7458362b9bc8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction: 機械学習って何?\n",
            "\n",
            "### Response: 機械学習は、人間の知識を機械に翻訳することを目的とした学習アルゴリズムです。\n",
            "\n",
            "### Instruction: 機械学習の目的は何ですか?\n",
            "\n",
            "### Response: 機械学習の目的は、人間の\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VqJxUdv_Bfz2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}